{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "from read_metadata_HIWI import read_metadata\n",
    "import subprocess\n",
    "from run_inference_HIWI import run_inference, extract_frames, video_to_frames, get_gpu_memory\n",
    "from export_tracks import export_tracks, calc_distance, get_color\n",
    "from detections_to_tracks import detections_to_tracks\n",
    "import pandas as pd \n",
    "import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "import datetime as dt\n",
    "\n",
    "import os\n",
    "from decord import VideoReader, cpu, gpu\n",
    "import cv2\n",
    "import subprocess as sp\n",
    "import tqdm\n",
    "\n",
    "import torch \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this is the only necessary input\n",
    "\n",
    "# tracks file\n",
    "tracks_file = 'C:/Users/meerkat/Documents/social_sleep/DATA/tracking_output/fewer_tracks_parameters/20190817/tracks_20190817_190002669000-final-final-final-final-final-final.npy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide a file path for the temporary images that will be created from the videos\n",
    "images_folder = \"C:/Users/meerkat/Documents/social_sleep/DATA/frames_for_finalizing/\"\n",
    "\n",
    "# where you want the tracking video to end up\n",
    "output_folder = 'C:/Users/meerkat/Documents/social_sleep/DATA/tracking_output/finalized_tracks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190817_190002669000-final-final-final-final-final-final'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_name  = tracks_file.split( \"/\")[ -1 ].split( \"_\", 1 )[ 1 ].split( \".\" )[ 0 ]\n",
    "\n",
    "vid_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the name of the original video. This will be necessary to pull in the .txt file from the server\n",
    "og_vid_name = vid_name.split( '-' )[ 0 ]\n",
    "\n",
    "# save the night this video came from\n",
    "start_timestamp = dt.datetime.strptime( og_vid_name, '%Y%m%d_%H%M%S%f' )\n",
    "\n",
    "start_timestamp - dt.timedelta( hours = 12 )\n",
    "\n",
    "night = dt.datetime.strftime( start_timestamp, '%Y%m%d' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input video\n",
    "input_video_file = os.path.join( 'Z:/baboon/archive/processed/video/thermal/2019_summer/cliff_data/mp4_files/viewpoint_1/T1020/', night, str( og_vid_name + '.mp4' ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/meerkat/Downloads/20190817\\\\20190817_190002669000.mp4'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_video_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what do these do?\n",
    "# %store vid_name\n",
    "# %store -r vid_name\n",
    "\n",
    "# metadata = read_metadata( vid_name ) ## expanded below\n",
    "\n",
    "### the only thing actually needed from this whole cell is the bit that sets the folder location where the videos for tracking are (metadata.folder_data_server)\n",
    "class struct:\n",
    "    pass\n",
    "\n",
    "## instantiate metadata\n",
    "metadata = struct()\n",
    "\n",
    "## this is the repository -- the main folder the project is occuring within\n",
    "#metadata.folder_main = \"C:/Users/meerkat/Documents/social_sleep/\"\n",
    "\n",
    "## this will use a folder that has all the images that will be turned into the video\n",
    "metadata.folder_images = images_folder\n",
    "\n",
    "## this will make a folder with the output of the video\n",
    "metadata.folder_output = os.path.join( output_folder, night )\n",
    "\n",
    "## I don't know what this is for\n",
    "#metadata.folder_annotations =  metadata.folder_data +  'annotations/'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5742\n"
     ]
    }
   ],
   "source": [
    "###### extracting frames from input video #######\n",
    "frames_already_extracted = False\n",
    "delete_frames = True\n",
    "\n",
    "overwrite = True \n",
    "\n",
    "# enter the interval of frames from the input videos that you would like to extract (interval = 1 means each frame will be used for tracking)\n",
    "image_interval = 1 ## image_interval is the step length between each frame to extract from the video. every = 1 pulls out every frame. every = 2 pulls out every other frame, etc.\n",
    "\n",
    "## set the start and end frames to be extracted from the input video. This makes it so we can limit the frames on which we do tracking to a certain part of the video. -1 means the whole video\n",
    "start= -1\n",
    "end= -1\n",
    "\n",
    "##### Plotting tracks hyperparameters #####\n",
    "steps = 10  # 90 # determines the number of timesteps into the past (with each frame = 1 timestep) the tail should be printed\n",
    "step_inc = 1 # 5 # determines the timestep interval at which a point for the tail is actually printed\n",
    "circle_radius = 3 # 20\n",
    "interpolation_factor = 10\n",
    "with_tail = True\n",
    "sample_range = range(1,1) # if you set 'sample_range' equal to this, it will actually go through all frames of the input video\n",
    "\n",
    "os.makedirs( ( os.path.join( metadata.folder_output ) ), exist_ok=True )\n",
    "\n",
    "video_out_file_name = \"video_\" + vid_name + \".mp4\" \n",
    "\n",
    "## assign the name of the video file for the video with the tracks\n",
    "video_out_file = os.path.join(metadata.folder_output, video_out_file_name)\n",
    "\n",
    "#### the following lines of code extract all the frames from the input video\n",
    "\n",
    "if frames_already_extracted != True:\n",
    "\n",
    "    ## not really sure what the os.path.join does here, but this just sets up the folder where the images will be extracted to\n",
    "    os.makedirs( ( os.path.join( metadata.folder_images ) ), exist_ok=True )\n",
    "\n",
    "    assert os.path.exists( input_video_file )  # assert the video file exists\n",
    "\n",
    "    # load the VideoReader\n",
    "    vr = VideoReader( input_video_file, ctx = cpu(0) )  # can set to cpu or gpu .. ctx=gpu(0)\n",
    "\n",
    "    if start < 0:  # if start isn't specified lets assume 0\n",
    "        start = 0\n",
    "    if end < 0:  # if end isn't specified assume the end of the video\n",
    "        end = len(vr)\n",
    "\n",
    "    ## you can change every to be image_interval everywhere below if you want\n",
    "    every = image_interval\n",
    "\n",
    "    ## make a list of the frame indices that we will pull out from the video (this is every frame when every = 1 )\n",
    "    frames_list = list(range(start, end, every ) )\n",
    "\n",
    "    ## start a counter of the number of images that are saved (why can't this be inferred from the length of frames_list?)\n",
    "    saved_count = 0\n",
    "\n",
    "    if every > 50 and len(frames_list) < 1000:  # this is faster for every > 25 frames and can fit in memory\n",
    "\n",
    "        frames = vr.get_batch(frames_list).asnumpy() ## pull out all the relevant frames as numpy arrays, in a single operation \n",
    "\n",
    "        for index, frame in zip(frames_list, frames):  # loop through the frames. For each frame...\n",
    "\n",
    "            save_path = os.path.join( metadata.folder_images, \"{:06d}.jpg\".format(index))  # create the save path. This will save each frame as a JPG with a 6 digit number as a file name (which indicates which frame in the original video it was) in the image folder input above\n",
    "\n",
    "            if not os.path.exists(save_path) or overwrite:  # if it doesn't exist or we want to overwrite anyways\n",
    "\n",
    "                cv2.imwrite(save_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))  # save the extracted image\n",
    "\n",
    "                saved_count += 1  # increment our counter by one\n",
    "\n",
    "    else:  # this is faster for every <25 and consumes small memory\n",
    "\n",
    "        try:\n",
    "\n",
    "            for index in frames_list:  # lets loop through the frames until the end\n",
    "\n",
    "                ## why can't the line above just read: for index in frames_list: ?? (it was for index in range( start, end )  Then we don't have to set the if statement below\n",
    "\n",
    "                frame = vr[ index ]  # read an image from the capture\n",
    "\n",
    "                # this shouldn't be needad anymore with my adjustment above... if index % every == 0:  # if this is a frame we want to write out based on the 'every' argument\n",
    "\n",
    "                save_path = os.path.join( metadata.folder_images, \"{:06d}.jpg\".format(index))  # create the save path. This will save each frame as a JPG with a 6 digit number as a file name (which indicates which frame in the original video it was) in the image folder input above\n",
    "\n",
    "                if not os.path.exists( save_path ) or overwrite:  # if it doesn't exist or we want to overwrite anyways\n",
    "\n",
    "                    cv2.imwrite(save_path, cv2.cvtColor(frame.asnumpy(), cv2.COLOR_RGB2BGR))  # save the extracted image\n",
    "\n",
    "                    saved_count += 1  # increment our counter by one\n",
    "\n",
    "        except:\n",
    "\n",
    "            frames = vr.get_batch(frames_list).asnumpy() ## pull out all the relevant frames as numpy arrays, in a single operation \n",
    "\n",
    "            for index, frame in zip(frames_list, frames):  # loop through the frames. For each frame...\n",
    "\n",
    "                save_path = os.path.join( metadata.folder_images, \"{:06d}.jpg\".format(index))  # create the save path. This will save each frame as a JPG with a 6 digit number as a file name (which indicates which frame in the original video it was) in the image folder input above\n",
    "\n",
    "                if not os.path.exists(save_path) or overwrite:  # if it doesn't exist or we want to overwrite anyways\n",
    "\n",
    "                    cv2.imwrite(save_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))  # save the extracted image\n",
    "\n",
    "                    saved_count += 1  # increment our counter by one\n",
    "\n",
    "    print( saved_count )  # and return the count of the images we saved\n",
    "\n",
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5741/5741 [19:55<00:00,  4.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "import pandas as pd, numpy as np, cv2, os, glob, matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from read_metadata_HIWI import read_metadata\n",
    "from tqdm import tqdm\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "os.path.join(metadata.folder_images, '*.jpg') # I don't think this does anything\n",
    "\n",
    "frame_files = sorted( glob.glob( os.path.join( metadata.folder_images, '*.jpg' ) ) ) # save the names of the frame files that were extracted from the input video above\n",
    "\n",
    "tracks = np.load( tracks_file, allow_pickle=True ) # load the tracks that we just saved above\n",
    "\n",
    "im = cv2.imread(frame_files[0]) # read in the first frame of the video\n",
    "\n",
    "fourcc = (cv2.VideoWriter_fourcc)(*'mp4v') # declare the codec for the video\n",
    "\n",
    "video_writer = cv2.VideoWriter( video_out_file, fourcc, 23.976, (im.shape[1], im.shape[0]) ) # instantiate the video at the desired file location with the codec declared above. Pull the dimensions for the video from the first frame extracted from the input video\n",
    "\n",
    "colors = np.random.uniform(size=(len(tracks))) # generate random numbers between 0 and 1 (with uniform probability). There will be as many numbers as there are tracks\n",
    "\n",
    "colors = [get_color(c) for c in colors] # turn each number into a color\n",
    "\n",
    "all_distance = [] # len(frame_files) # instantiate an empty list\n",
    "\n",
    "if len(sample_range) == 0: # if the sample_range has been set to the default (i.e. essentially hasn't been defined)\n",
    "\n",
    "    sample_range = range(1, len(frame_files), 1) # set the range equal to the entire input video\n",
    "\n",
    "for frame_ind in tqdm(sample_range): # loop through the frames of the input video. For each frame...\n",
    "\n",
    "    im = cv2.imread(frame_files[frame_ind]) # read the frame in using cv2\n",
    "\n",
    "    for track_ind, track in enumerate(tracks): # loop through the tracks. For each track...\n",
    "\n",
    "        rel_frame = frame_ind - track['first_frame'] # find the number of this frame compared to the frame on which the track starts from\n",
    "\n",
    "        if rel_frame >= 0 and track['last_frame'] > frame_ind: # if the current frame comes after the track has started and before the track has ended...\n",
    "\n",
    "            center_pos = track['track'][rel_frame] # find and save the position of the track on this frame\n",
    "\n",
    "            if not np.isnan( np.sum( center_pos ) ):                        \n",
    "\n",
    "                cv2.circle(im, (int(center_pos[0]), int(center_pos[1])), circle_radius, colors[track_ind], -1) # print a circle on the frame representing the center position of the current detection (i.e. the location of the track at this frame)\n",
    "                cv2.putText(im, str(track_ind), (int(center_pos[0] + 10 ), int(center_pos[1] + 10 )), 0, 1, colors[track_ind],3) # label the location of the current detection of the track with the index of the track\n",
    "\n",
    "                if with_tail: # if there should be a tail printed on the frame showing where the track had been in previous frames...\n",
    "\n",
    "                    if rel_frame > steps: # if the number of frames from the start of the track to the current frame are greater than the number of steps to include in the tail...\n",
    "\n",
    "                        pos = track['track'][ range( rel_frame - steps, rel_frame - step_inc, step_inc) ] # find the position of the track at each time for which a tail point should be included (this is determined by steps, which determines how many timesteps back (with each frame = 1 time step) the tail should represent, and step_inc, which determines the interval of timesteps for which a tail point is actually printed)\n",
    "\n",
    "                        interp_pos = np.zeros((len(range(step_inc, len(pos)*interpolation_factor-interpolation_factor, 1)),2)) # sets up a two column array that will be filled with the interpolation tail points to print\n",
    "\n",
    "                        interp = interpolate.interp1d(range(step_inc, len(pos)*interpolation_factor, step_inc*interpolation_factor), pos[:,0], kind = \"linear\") # do a linear interpolation on the x coordinates of the previous positions of this track to be used in the tail that were extracted above\n",
    "\n",
    "                        interp_pos[:,0] = gaussian_filter1d(interp(range(step_inc, len(pos)*interpolation_factor-interpolation_factor, 1)),interpolation_factor) # set the x coordinates within the array to be printed equal to the linear interpolation (with some guassian filtering?)\n",
    "\n",
    "                        interp = interpolate.interp1d(range(step_inc, len(pos)*interpolation_factor, step_inc*interpolation_factor), pos[:,1], kind = \"linear\") # do a linear interpolation on the y coordinates of the previous positions of this track to be used in the tail that were extracted above\n",
    "\n",
    "                        interp_pos[:,1] = gaussian_filter1d(interp(range(step_inc, len(pos)*interpolation_factor-interpolation_factor, 1)),interpolation_factor) # set the y coordinates within the array to be printed equal to the linear interpolation (with some guassian filtering?)\n",
    "\n",
    "                        size_vec = np.power(2,np.linspace(0.5,circle_radius,len(range(0,len(interp_pos),1)))) # make an array of the size that each point in the tail should be printed as, with earlier points being printed smaller\n",
    "\n",
    "                        for inc in range(0,len(interp_pos),1): # loop through the indices of the coordinates of the tail points. For each tail point...\n",
    "\n",
    "                            pos_loc = interp_pos[ inc ] # extract the coordinate of the point\n",
    "\n",
    "                            distance = calc_distance(pos_loc, center_pos) # calculate the distance between this tail point and the current location of the track\n",
    "                            # if distance < circle_radius:\n",
    "                            #     continue\n",
    "                            if not np.isnan( np.sum( pos_loc ) ):\n",
    "\n",
    "                                cv2.circle(im, (int(pos_loc[0]), int(pos_loc[1])), int(np.round(size_vec[inc])), colors[track_ind], -1) # print the tail point at these coordinates, with appropriate size according to that calculated above\n",
    "\n",
    "    video_writer.write( im ) # write the printed image with the tracks on it to the video\n",
    "\n",
    "video_writer.release() # release the video\n",
    "\n",
    "\n",
    "\n",
    "files_in_directory = os.listdir(metadata.folder_images) # make a list of the image files of the frames from the input video\n",
    "\n",
    "filtered_files = [file for file in files_in_directory if file.endswith('.jpg')] # filter these to make sure they are the images (i.e. end with a 'jpg')\n",
    "\n",
    "if delete_frames == True:\n",
    "\n",
    "    ## delete the image files of the frames of the input video from the folder\n",
    "    for file in filtered_files:\n",
    "        path_to_file = os.path.join(metadata.folder_images, file)\n",
    "        os.remove(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## turn the npy tracks into a dataframe and save the dataframe in the finalized tracks folder as a csv\n",
    "\n",
    "all_tracking = pd.DataFrame({'frame':[],  'id':[],  'x':[],  'y':[] }) # start a dataframe that will be filled with all the location of all the tracks for the video\n",
    "\n",
    "all_distance = [] # len(frame_files) # instantiate an empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track_ind, track in enumerate( tracks ):\n",
    "    \n",
    "    track_frames = list( range( track['first_frame'], track['last_frame'] + 1 ) )\n",
    "    \n",
    "    to_append = pd.DataFrame( {'frame': pd.Series( track_frames ), 'id': [ track_ind ] * len( track_frames ), 'x': pd.Series( track['track'][:,0] ) ,  'y': pd.Series( track['track'][:,1] ) } )    \n",
    "\n",
    "    all_tracking = all_tracking.append( to_append, ignore_index = True )\n",
    "    \n",
    "all_tracking[ 'vid_name' ] =  og_vid_name\n",
    "\n",
    "all_tracking = all_tracking.astype( { 'frame': int, 'id': int, 'x': float, 'y': float } )\n",
    "\n",
    "all_tracking.to_csv( os.path.join( metadata.folder_output, 'tracks_' + vid_name + '.csv' ), index=False) # write the csv with all the tracks to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now copy the tracks file and the .txt file for the night over to the finalized tracks folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_txt = os.path.join( 'Z:/baboon/archive/processed/video/thermal/2019_summer/cliff_data/mp4_files/viewpoint_1/T1020/', night, og_vid_name + '.txt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Z:/baboon/archive/processed/video/thermal/2019_summer/cliff_data/mp4_files/viewpoint_1/T1020/20190815\\\\20190815_163505281000.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c54d2c7e3dd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## copy associated txt file into the finalized tracks folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mcurrent_txt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfolder_output\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m             \u001b[1;31m# macOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Z:/baboon/archive/processed/video/thermal/2019_summer/cliff_data/mp4_files/viewpoint_1/T1020/20190815\\\\20190815_163505281000.txt'"
     ]
    }
   ],
   "source": [
    "## copy associated txt file into the finalized tracks folder\n",
    "shutil.copy( current_txt, metadata.folder_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/meerkat/Documents/thermal_baboon/RESULTS/tracking_output/viewpoint_1/finalized_tracks/20190817\\\\tracks_20190817_190002669000-final-final-final-final-final-final.npy'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## copy the tracks file into the finalized tracks folder\n",
    "shutil.copy( tracks_file, metadata.folder_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
